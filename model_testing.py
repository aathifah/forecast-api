# -*- coding: utf-8 -*-
"""model_testing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B_Ne_wQhdVC_1DhuCTc3dMYIaQh-qaKK
"""

from joblib import Parallel, delayed
from tqdm import tqdm
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_percentage_error, make_scorer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit
from scipy.optimize import minimize
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from pmdarima import auto_arima
from pandas import ExcelWriter
import warnings
import os
import pickle


warnings.filterwarnings("ignore")


# Forecasting Methods
def forecast_ma6(series):
    return np.mean(series[-6:])

def forecast_wma(series, actual=None, window=6):
    if len(series) < window:
        return np.nan
    if actual is None:
        return np.mean(series[-window:])
    def objective(weights):
        weights = np.array(weights)
        weights /= weights.sum()
        forecast = np.sum(series[-window:] * weights)
        return abs(forecast - actual)
    bounds = [(0, 1)] * window
    constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
    init_weights = np.repeat(1 / window, window)
    result = minimize(objective, init_weights, bounds=bounds, constraints=constraints)
    if result.success:
        weights = result.x / result.x.sum()
        forecast = np.sum(series[-window:] * weights)
        return max(forecast, 0)
    else:
        return max(np.mean(series[-window:]), 0)

def forecast_ets(series, val_size=3):
    if len(series) < (val_size + 3):
        return np.nan
    best_mape = np.inf
    best_forecast = np.nan
    param_grid = {
        'smoothing_level': np.linspace(0.01, 0.99, 5),
        'smoothing_slope': [None] + list(np.linspace(0.01, 0.99, 5))
    }
    train = series[:-val_size]
    val = series[-val_size:]
    for alpha in param_grid['smoothing_level']:
        for beta in param_grid['smoothing_slope']:
            try:
                model = ExponentialSmoothing(train, trend='add' if beta is not None else None, seasonal=None, initialization_method="estimated")
                fit = model.fit(smoothing_level=alpha, smoothing_slope=beta)
                forecast_val = fit.forecast(len(val))
                mape_val = mean_absolute_percentage_error(val, forecast_val)
                if mape_val < best_mape:
                    best_mape = mape_val
                    forecast = fit.forecast(1)[0]
                    best_forecast = max(forecast, 0)
            except:
                continue
    if np.isnan(best_forecast):
        try:
            model = ExponentialSmoothing(series, trend=None, seasonal=None, initialization_method="estimated")
            fit = model.fit()
            best_forecast = max(fit.forecast(1)[0], 0)
        except:
            best_forecast = np.nan
    return best_forecast

def forecast_arima(series, val_size=3):
    if len(series) < val_size + 3:
        return np.nan
    train = series[:-val_size]
    val = series[-val_size:]
    try:
        model = auto_arima(train, seasonal=False, suppress_warnings=True, stepwise=True, error_action='ignore')
        preds = model.predict(n_periods=val_size)
        mape_val = mean_absolute_percentage_error(val, preds)
        if mape_val < 0.3:
            return model.predict(n_periods=1)[0]
        else:
            full_model = auto_arima(series, seasonal=False, suppress_warnings=True, stepwise=True, error_action='ignore')
            return full_model.predict(n_periods=1)[0]
    except:
        return np.nan

# Helper Functions
mape_scorer_sklearn = make_scorer(mean_absolute_percentage_error, greater_is_better=False)

def sample_data(X, y, sample_frac=0.5, random_state=42):
    return (X.loc[y.sample(frac=sample_frac, random_state=random_state).index], y.sample(frac=sample_frac, random_state=random_state)) if len(X) > 50 else (X, y)

def tune_model_if_needed(model_name, model, X_train, y_train, X_test, actual, initial_pred, mape_threshold=0.3):
    if np.isnan(initial_pred) or np.isnan(actual):
        return initial_pred, model
    if mean_absolute_percentage_error([actual], [initial_pred]) <= mape_threshold:
        return initial_pred, model
    X_sample, y_sample = sample_data(X_train, y_train)
    if len(X_sample) < 2:
        return initial_pred, model
    param_dist = {
        'RF': {
            'n_estimators': [50, 100, 150],
            'max_depth': [None, 5, 10],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        },
        'XGB': {
            'n_estimators': [50, 100, 150],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.05, 0.1],
            'subsample': [0.6, 0.8, 1.0]
        },
        'LINREG': {}
    }
    if model_name not in param_dist:
        return initial_pred, model
    tscv = TimeSeriesSplit(n_splits=3)
    try:
        rnd_search = RandomizedSearchCV(
            model,
            param_distributions=param_dist[model_name],
            n_iter=10 if param_dist[model_name] else 1,
            cv=tscv,
            scoring=mape_scorer_sklearn,
            n_jobs=-1,
            random_state=42
        )
        rnd_search.fit(X_sample, y_sample)
        tuned_pred = rnd_search.best_estimator_.predict(X_test)[0]
        return tuned_pred, rnd_search.best_estimator_
    except:
        return initial_pred, model

def hybrid_error(actual, forecast):
    actual = float(actual)
    forecast = float(forecast)
    if np.isnan(actual) or np.isnan(forecast):
        return np.inf
    if actual == 0:
        return 2 * abs(forecast - actual) / (abs(forecast) + abs(actual) + 1e-8)
    else:
        return abs((actual - forecast) / actual)

# === Main Forecast per PART_NO ===
# Proses Forecast per PART_NO
def process_part(part, part_df, test_months, full_df):
    part_results = []
    part_history = part_df.set_index('MONTH').resample('MS').sum().fillna(0)

    for target_month in test_months:
        train_df = part_df[part_df['MONTH'] < target_month].copy()
        test_df = part_df[part_df['MONTH'] == target_month].copy()

        # Ambil 6 bulan terakhir sebelum target_month
        six_months_prior = pd.date_range(end=target_month - pd.offsets.MonthBegin(1), periods=6, freq='MS')
        recent_6_months_df = train_df[train_df['MONTH'].isin(six_months_prior)]

        # Cek demand 6 bulan terakhir berturut-turut (tidak ada demand sama sekali)
        last_6_qty = (
            train_df.set_index('MONTH')
            .reindex(six_months_prior)['ORIGINAL_SHIPPING_QTY']
            .fillna(0)
            .values
        )

        # Jika 6 bulan berturut-turut tidak ada demand, forecast = 0
        if np.all(last_6_qty == 0):
            part_results.append({
                'PART_NO': part,
                'MONTH': target_month.strftime('%Y-%m'),
                'FORECAST': 0,
                'ACTUAL': test_df['ORIGINAL_SHIPPING_QTY'].values[0] if not test_df.empty else np.nan,
                'HYBRID_ERROR': None,
                'BEST_MODEL': 'NONE',
                'NOTE': 'No Demand in last 6 months'
            })
            continue

        history = train_df.set_index('MONTH').resample('MS').sum().fillna(0)
        series = history['ORIGINAL_SHIPPING_QTY'].values
        actual = test_df['ORIGINAL_SHIPPING_QTY'].values[0] if not test_df.empty else np.nan

        # Get all forecasting methods
        preds = {
            'MA6': forecast_ma6(series),
            'WMA': forecast_wma(pd.Series(series), actual=actual),
            'ETS': forecast_ets(series),
            'ARIMA': forecast_arima(series)
        }

        features = ['LAG_1', 'LAG_2', 'LAG_3', 'LAG_4', 'LAG_5', 'LAG_6',
            'MONTH_NUM', 'YEAR', 'MONTH_SIN', 'MONTH_COS']
        cat_cols = ['PART_NAME', 'TOPAS_ORDER_TYPE', 'CREATED_DEMAND_FLAG', 'CUST_TYPE2']
        for col in cat_cols:
            le = LabelEncoder()
            all_vals = pd.concat([train_df[col], test_df[col]])
            le.fit(all_vals)
            train_df[col] = le.transform(train_df[col])
            test_df[col] = le.transform(test_df[col])
            features.append(col)

        X_train, y_train = train_df[features], train_df['ORIGINAL_SHIPPING_QTY']
        X_test = test_df[features] if not test_df.empty else None

        # Buang NaN dari training data saja (test tetap dipakai meski NaN)
        mask_valid = X_train.notna().all(axis=1)
        X_train = X_train[mask_valid]
        y_train = y_train[mask_valid]

        ml_models = {
            'LINREG': LinearRegression(),
            'RF': RandomForestRegressor(n_estimators=100, random_state=42),
            'XGB': XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
        }

        for name, model in ml_models.items():
            if X_train is None or len(X_train) == 0:
                preds[name] = np.nan
                continue

            model.fit(X_train, y_train)

            if X_test is not None and not X_test.empty:
                if X_test.isnull().all(axis=1).any():
                    preds[name] = 0
                else:
                    pred = model.predict(X_test)[0]
                    tuned_pred, best_model = tune_model_if_needed(name, model, X_train, y_train, X_test, actual, pred)
                    preds[name] = tuned_pred
                    ml_models[name] = best_model
            else:
                preds[name] = np.nan

        # Calculate errors for all methods
        errors = {m: hybrid_error(actual, p) for m, p in preds.items()}
        best_model_name = min(errors, key=errors.get)

        part_results.append({
            'PART_NO': part,
            'MONTH': target_month.strftime('%Y-%m'),
            'FORECAST': round(preds[best_model_name]) if not np.isnan(preds[best_model_name]) else None,
            'ACTUAL': actual,
            'HYBRID_ERROR': f"{errors[best_model_name] * 100:.2f}%" if errors[best_model_name] != np.inf else None,
            'BEST_MODEL': best_model_name
        })

        # ⬇ Tambahan untuk menyimpan model terbaik
        if best_model_name in ml_models:
            # Ambil model terbaik
            best_model_obj = ml_models[best_model_name]

            # Buat folder kalau belum ada
            os.makedirs('saved_models', exist_ok=True)

            # Simpan model sebagai .pkl
            model_path = f"saved_models/model_{part}.pkl"
            with open(model_path, 'wb') as f:
                pickle.dump({
                    'model': best_model_obj,
                    'model_type': best_model_name,
                    'features': features  # penting untuk API nanti
                }, f)

    return part_results

def save_forecast_to_excel(original_df, final_df, output_file):
    try:
        if os.path.exists(output_file):
            os.remove(output_file)

        with ExcelWriter(output_file, engine="openpyxl", mode='w') as writer:
            original_df.to_excel(writer, sheet_name="dataset", index=False)
            final_df.to_excel(writer, sheet_name="testing_forecast", index=False)
            writer.book.save(output_file)

            # ✅ Debugging tambahan untuk file hasil
            if os.path.exists(output_file):
                file_size = os.path.getsize(output_file)
                print(f"📁 File hasil ditemukan. Ukuran: {file_size / 1024:.2f} KB")
            else:
                print("❌ File hasil forecast TIDAK ditemukan setelah proses simpan.")

    except Exception as e:
        print(f"❌ Gagal menyimpan file Excel: {e}")

# === Run Combined Forecast (Backtest) ===
def run_combined_forecast(file_path='uploads/dataset.xlsx'):
    print(f"📥 Membaca data dari: {file_path}")
    df = pd.read_excel(file_path)
    df['MONTH'] = pd.to_datetime(df['MONTH'].astype(str), format='%Y%m')
    df = df.groupby(['PART_NO', 'MONTH'], as_index=False).agg({
        'ORIGINAL_SHIPPING_QTY': 'sum',
        'PART_NAME': 'first',
        'TOPAS_ORDER_TYPE': 'first',
        'CREATED_DEMAND_FLAG': 'first',
        'CUST_TYPE2': 'first'
    })

    df['MONTH_NUM'] = df['MONTH'].dt.month
    df['YEAR'] = df['MONTH'].dt.year
    df['MONTH_SIN'] = np.sin(2 * np.pi * df['MONTH_NUM'] / 12)
    df['MONTH_COS'] = np.cos(2 * np.pi * df['MONTH_NUM'] / 12)
    for lag in range(1, 7):
        df[f'LAG_{lag}'] = df.groupby('PART_NO')['ORIGINAL_SHIPPING_QTY'].shift(lag)

    latest_year = df['YEAR'].max()
    latest_year_months = df[df['YEAR'] == latest_year]['MONTH'].sort_values().unique()
    test_months = pd.to_datetime(latest_year_months[-4:])

    part_list = df['PART_NO'].unique()
    print(f"🔄 Memulai proses forecast untuk {len(part_list)} part...")

    results_nested = Parallel(n_jobs=-1)(
        delayed(process_part)(part, df[df['PART_NO'] == part].sort_values('MONTH'), test_months, df)
        for part in tqdm(part_list, desc="Processing parts")
    )

    results = [item for sublist in results_nested for item in sublist]
    final_df = pd.DataFrame(results)
    output_file = 'uploads/testing_forecast.xlsx'
    os.makedirs('uploads', exist_ok=True)

    original_df = pd.read_excel(file_path)
    if final_df.empty:
        print("⚠️ FINAL_DF kosong — hasil forecast tidak tersedia.")
    else:
        print(f"✅ Forecast berhasil dibuat dengan {len(final_df)} baris.")

    save_forecast_to_excel(original_df, final_df, output_file)
    return final_df

# Jika ingin dijalankan langsung tanpa Excel
# if __name__ == "__main__":
#    run_combined_forecast()
